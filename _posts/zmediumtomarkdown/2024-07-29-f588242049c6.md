---
title: "【Unity】Displacement Map"
author: "帽捲"
date: 2024-07-29T01:38:54.139+0000
last_modified_at: 2024-07-29T01:38:54.139+0000
categories: ["Maochinn"]
tags: ["unity","computer-graphics"]
description: "本篇要在Unity來解決一個用OpenGL很容易的問題，也就是位移貼圖(Displacement Map)，同時希望能夠動態調整與不同位移程度的mesh，舉例來說一個簡單的應用，總共會有三種變形程度的Mesh，分別表示0.0, 0.5…"
image:
  path: /assets/f588242049c6/1*cMW6ZmpOT0rfDJ4_zha5tg.png
render_with_liquid: false
---

### 【Unity】Displacement Map

本篇要在Unity來解決一個用OpenGL很容易的問題，也就是 [位移貼圖](https://en.wikipedia.org/wiki/Displacement_mapping){:target="_blank"} \(Displacement Map\)，同時希望能夠動態調整與不同位移程度的mesh，舉例來說一個簡單的應用，總共會有三種變形程度的Mesh，分別表示0\.0, 0\.5, 1\.0的變形狀況，隨機給定0~1的值去內插。


[![Warping Mesh](/assets/f588242049c6/9029_hqdefault.jpg "Warping Mesh")](https://www.youtube.com/watch?v=xEZLRzWZ4BU){:target="_blank"}


事實上，如果不拘泥於一定要用Displacement map的話，至少有4種方法，分別是
1. 上中: **GPU\-based** Multi\-texture warped grid
2. 左下: CPU\-based Multi\-shape warped grid \(Skinned Mesh Renderer\)
3. 下中: CPU\-based Multi\-texture warped grid
4. 右中: CPU\-based Multi\-UV Warped grid


事實上， **第2點** 就是對應 [【Blender】客製化建立Shape Keys](https://medium.com/@maochinn/blender-%E5%AE%A2%E8%A3%BD%E5%8C%96%E5%BB%BA%E7%AB%8Bshape-keys-20537e3c427d?source=your_stories_page-------------------------------------){:target="_blank"} ，可以在Blender利用不同的變形mesh建立多個shape，並輸出\.fbx， **第4點** 則是對應 [【Blender】客製化建立Attributes](https://medium.com/@maochinn/blender-%E5%AE%A2%E8%A3%BD%E5%8C%96%E5%BB%BA%E7%AB%8Battributes-a1c22052f276?source=your_stories_page-------------------------------------){:target="_blank"} ，把不同的變形mesh建立成多個Attribute，並輸出\.obj，然後到Unity的Shader中用attribute自己內插。

最後， [【Blender】客製化建立Texture](https://medium.com/maochinn/blender-%E5%AE%A2%E8%A3%BD%E5%8C%96%E5%BB%BA%E7%AB%8Btexture-8b414b22f7fb?source=your_stories_page-------------------------------------){:target="_blank"} 則是對應 **第1點** 與 **第3點** ，也就是本篇的重點，簡單來說，就是透過Blender將變形的mesh轉換成displacement map，差異在於，前者是使用Shader計算內插結果，後者是Script計算內插結果。

首先，先複習一下Displacement Map，基本上就是使用texture上的texel做為vertex移動的依據，例如最常見的height map就是一種Displacement Map，其利用texel的值做高低的位移，也就是單一方向的位移，倘若RGB都使用到，那基本上XYZ三維空間的位移。

同時，因為移動的距離通常較為精細，而一般pixel使用\[0, 255\]的值域範圍顯然不夠用，因此比起用unsigned char\(8 bits\)更常用float\(32 bits\)去儲存，而這種格式更常見的則是用在所謂的HDR texture，其為了要儲存照片中更多的色彩細節，因此需要更多的細分色階去儲存。


![[https://upload\.wikimedia\.org/wikipedia/commons/a/a4/Displacement\.jpg](https://upload.wikimedia.org/wikipedia/commons/a/a4/Displacement.jpg){:target="_blank"}](/assets/f588242049c6/0*TsKicZ-bHrKsTPxq.jpg)

[https://upload\.wikimedia\.org/wikipedia/commons/a/a4/Displacement\.jpg](https://upload.wikimedia.org/wikipedia/commons/a/a4/Displacement.jpg){:target="_blank"}

但是在Unity，使用half float\(16 bit\)更為常見，其只需要16\*4 = 64 bits，顯然這個數字對於系統更友善一些，只是精準度較差，但在遊戲中基本上夠用了。


[![](https://techarthub.com/wp-content/uploads/unity-texture-compression-cheat-sheet-featured.jpg)](https://www.techarthub.com/unity-texture-compression-cheat-sheet/){:target="_blank"}


[https://discussions\.unity\.com/t/floating\-point\-textures/775105](https://discussions.unity.com/t/floating-point-textures/775105){:target="_blank"}

如果要使用HDR texture去做為Displacement Map會遇到許多問題，或者說，在Unity Shader中要正確使用HDR Texture至少有以下兩種方法。

簡單來說，就是在腳本中建立Texture，或者是從外部匯入Texture，然後再將其assign到Shader中計算內插，前者是在Runtime，也就是執行下去的時候才會建立一張displacement map，後者則是Offline事先建立一個圖檔，然後在專案中轉換成displacement map。值得注意的是，本篇專注於介紹在Unity如何正確使用HDR Texture，因此關於內插或是實作細節就不會一一介紹。
#### 從腳本建立HDR Texture

首先是一個比較單純的方法，但是比較麻煩一些，就是先寫一個腳本用來產生HDR texture，再把HDR Texture assign到Shader裡面，因此要先寫C\#腳本用TextureFormat\.RGBAHalf 產生 Texture2D，
```csharp
var texture = new Texture2D(table_width, table_height, TextureFormat.RGBAHalf, false);
```

然後就照著官方的 [教學](https://docs.unity3d.com/ScriptReference/Texture2D.Apply.html){:target="_blank"} 去apply，每個Pixel使用Color去填，Color是用float去存每個顏色，基本上要把值域壓到\[0, 1\]，因此，舉例來說，如果本來的x的值是0~900，y的值是0~400，那麼在塞到Color前就要先除，只是這邊不用擔心如果值大於1會被clamp，因為是使用half去存，所以超過1的數字仍然會被保留，因此，理論上，你也可以不用壓到\[0, 1\]，但是習慣跟檢視上我們還是習慣normalize，整個過程類似這樣
```csharp
for (int j = 0; j < texture.height; j++)
{
    for (int i = 0; i < texture.width; i++)
    {
        float x;  // TODO
        float y;  // TODO

        Color color;
        color.r = x / 900.0f;
        color.g = y / 400.0f;
        color.b = 0.0f;
        color.a = 1.0f;

        texture.SetPixel(i, j, color);
    }
}
texture.Apply();
```

其中XY座標就看你要怎麼輸入進來，可以透過其他貼圖或是寫死在腳本裡面，接著再把Texture設置到Renderer的Material中，
```java
Renderer renderer = GetComponent<Renderer>();
renderer.material.SetTexture("_DisplacementMap", texture);

this.transform.localScale = new Vector3(900.0f, 400.0f, 1.0f);
```

其中，掛載這個Script的GameObject長得如下，有4個Component，Transform、Mesh Filter、Mesh Renderer、Script、Material\(Shader\)，可以注意到Transform中Scale會被我設定為\(900, 400, 1\)，這是因為我們在填displacement map時有除以\(900, 400\)，因此依照這個Map位移出來的Mesh會在0~1之間，所以要把每個vertex再乘回來。


![GameObject](/assets/f588242049c6/1*rKRBsQMgePOlnHSTPmw45Q.png)

GameObject

其中比較重要的是Mesh是我先在Blender建模好的，總共21\*9=189個vertices，主要是因為我的Map也是21\*9個pixel，但其實不用一一對應沒關係。Material則是自己寫的Shader，其中一個Texture是預設的，另一個是Displacement Map


![](/assets/f588242049c6/1*XgOPoWuL0ziQEgGmKmtjFg.png)



![Mesh、Material](/assets/f588242049c6/1*roBy4-JmFX2cvv-7NIfsDw.png)

Mesh、Material

Shader的部分長得像這樣，重點在vertex shader，因為Mesh當初是我自己建模的，我有設定好左下角是\(0, 0\)，右上角是\(1, 1\)，因此這邊直接拿Position當作UV使用，用 _tex2D_ 去對displacement map採樣，得到一組座標，然後再將該座標從Model Space轉換到Clip Space拿來當作vertex shader的輸出。
```java
v2f vert(appdata v)
{
    v2f o;
    o.vertex = UnityObjectToClipPos(v.vertex);
    o.uv = v.vertex.xy; // predefine: grid in model space == uv space

    float2 uv = v.vertex.xy;
    float4 vertex = tex2D(_DisplacementMap, _DisplacementMap_TexelSize, uv);


    o.vertex = UnityObjectToClipPos(vertex);

    return o;
}
```

可以注意到 _tex2D\( \)_ 是我自己寫的，簡單來說就是拿UV去對displacement map採樣，但是採樣時要解決 [Half\-texel Offset](../cd004cee4968/) ，細節這邊不詳述。
```go
float4 tex2D(sampler2D map, float2 size, float2 uv) {
    // Filter Mode is Bilinear, not necessary if mode is Point(Nearest)
    // scale by center
    uv -= 0.5;                  // [0, 1] -> [-0.5, 0.5]
    uv *= (size - 1) / size;    
    uv += 0.5;                  // [-0.5, 0.5] -> [0, 1]

    return tex2Dlod(map, float4(uv, 0.0, 1.0));
}
```

如此就可以將mesh變形，舉個例子來說，\(1, 1\)這個位置的vertex如果完全不做任何事情，也就是不做位移的話，同時因為Scale設定成\(900, 400\)，那就會被 _UnityObjectToClipPos_ 轉換到\(1\.0 \* 900, 1\.0 \* 400\)再轉換到clip space。

一個比較實際的例子是，假設Displacement Map在UV是\(1, 1\)對應的RG值是\(0\.3, 1\.3\)，那麼此時在
```java
float4 vertex = tex2D(_DisplacementMap, _DisplacementMap_TexelSize, uv);
```

這行得到的值就是 _vertex_ 的值是\(0\.3, 1\.3, 0\.0, 1\.0\)，
```ini
o.vertex = UnityObjectToClipPos(vertex);
```

接著 _UnityObjectToClipPos_ 則是會將\(0\.3, 1\.3, 0\.0, 1\.0\)乘上\(900, 400, 1\.0, 1\.0\)再轉換到clip space，也就是最終\(1, 1\)這個位置的值會變成\(0\.3 \* 900, 1\.3 \* 400\) = \(270, 520\)。
#### 從 **外部匯入Texture**

實際上，大多數的情況下，Table或是Map都是offline產生的，也就是可能會先將map儲存成圖檔之類的，而不會像這樣寫死在程式碼中，再用腳本生成，因此比較直覺的想法是，不透過腳本直接將Map放到Shader裡面計算，除了讓事情比較單純都在Shader中計算之外，在GPU計算比在CPU計算還要有效率，雖然這牽涉到Map是否會頻繁更新等其他更實務的問題，這邊就不展開。

而是這麼做的好處是，不用在Unity掛腳本，可以在別的地方事先輸出好Map的圖檔，如果要替換直接丟到專案中，這樣也很容易替換


![](/assets/f588242049c6/1*a-YrLFnwYg47H0mVjCR8tw.png)


其中，Map會使用\.exr之類的HDR圖片格式，而不是使用常見的png, jpg等，只是坑就在這裡。

首先，要記得把Format改成RGBA Half，值才不會跑掉，更準確地來說，要看Texture2D\.format，只有RGBAHalf、RGBAFloat才會用float去存，其他格式都會把Map中的值clamp to \[0, 1\]，也就是雖然Map原始的值有超出0~1範圍的話會被直接壓到0或1。


![](/assets/f588242049c6/1*CvKoBd8HmjlaZkda_DO82g.png)


另外，介面上只讓你調成half，或許是部分平台不支援32bit float。

然後還沒完，Vertex Shader的部分大同小異，但是要記得做Gamma **反校正** ，至於什麼是 [Gamma校正](https://en.wikipedia.org/wiki/Gamma_correction){:target="_blank"} 就超出本篇範圍，簡單來說就是要把值做2\.2次方，其中，將Linear Space經過Gamma=2\.2轉換出來的空間基本上就是所謂的sRGB。
```ini
vertex.rgb = pow(vertex.rgb, 2.2);
```

因此，這行就是將Displacement Map的值從sRGB\(為了配合API，姑且稱為Gamma Space\)轉回Linear Space，因為我們定義好的Texture是在Linear Space，這個轉換的過程可以用Unity提供的 _GammaToLinearSpaceExact_ 。
```java
v2f vert(appdata v)
{
    v2f o;
    o.vertex = UnityObjectToClipPos(v.vertex);
    o.uv = v.vertex.xy; // predefine: grid in model space == uv space

    sampler2D map0 = _Warping < 0.5 ? _LowerMap : _MiddleMap;
    sampler2D map1 = _Warping < 0.5 ? _MiddleMap : _UpperMap;

    float2 uv = v.vertex.xy;
    float4 vertex = tex2D(_DisplacementMap, _DisplacementMap_TexelSize, uv);
     
    // for Linear HDR texture, if project setting is GAMMA SPACE, we have to transform texel to linear space
    // Because Unity would Linear HDR Texture transform to Gamma(2.2) Texture, automatically
    // vertex.rgb = pow(vertex.rgb, 2.2)
    // vertex.rgb = GammaToLinearSpace(vertex.rgb);
    vertex.r = GammaToLinearSpaceExact(vertex.r);
    vertex.g = GammaToLinearSpaceExact(vertex.g);
    vertex.b = GammaToLinearSpaceExact(vertex.b);

    // uv space == model space
    o.vertex = UnityObjectToClipPos(vertex);

    return o;
}
```

這邊一定會很疑惑，為什麼我要做 **反校正** ？我甚麼時候做轉換的？答案是，Unity幫你做轉換的，當你把HDR圖檔import到專案的時候Unity會偵測到是HDR檔案，會幫你把值從Linear Space轉換到Gamma Space方便後續檢視，但是如果你是在腳本自己建立HDR Map的話，那Unity就不會這麼貼心的去 **竄改你的值** 。因此 **從外部匯入Texture** 的壞處是，要記得在 **多寫一些轉換。**

那有沒有辦法去讓Unity不要竄改你的值呢？參考 [這篇](https://forum.unity.com/threads/how-to-get-argbfloat-render-texture-data-without-colorspace-interfering.770558/){:target="_blank"} ，可以，告訴Unity整個專案都是在Linear Space下計算，這樣自然不會幫你轉換到Gamma Space，但這樣的設置傷筋動骨、茲事體大，因此比較簡單的做法還是在自己做反校正。


[![](https://unity3d.com/files/images/ogimg.jpg)](https://docs.unity3d.com/Manual/LinearRendering-LinearTextures.html){:target="_blank"}



[![](https://unity3d.com/files/images/ogimg.jpg)](https://docs.unity3d.com/Manual/LinearRendering-LinearOrGammaWorkflow.html){:target="_blank"}


但是要注意的是，實際應用上，這兩者都是在Runtime動態調整位移程度，藉由三個不同變形程度的Mesh，差異在於，前者會在腳本中會內插出結果的Mesh，再建立出HDR Texture的Map，然後assign到shader，後者則是直接匯入圖檔，接著全部assign到shader，然後在shader計算內插結果。

另外補充一下相同應用下其他兩個方法，也就是開頭提到的其他方式，也就是不使用Map的話。

_CPU\-based Multi\-shape warped grid_ 就是借用Animtation的Skinned Mesh Renderer，把變形後的Mesh變成一個Shape去做內插。又或者 _CPU\-based Multi\-UV Warped grid_ 就是直接把map中21\*9的值直接當作21\*9個vertex的attribute，自己寫Shader內插。這兩者缺點是，vertex跟map等於綁在一起，如果map要改變則整個mesh也要換掉。

總之，如果有做成功，基本上四個方法結果應該一致，只是自己取捨哪種方法比較好。

基本上如果完全不想寫程式，那就是把他用Blender之類的把mesh編輯成Skinned Mesh，如果願意寫Unity的Shader就把變形後的結果存在每個vertex上，在shader中內插，接下來如果考量到替換方便，才會使用displacement map，但這又分為offline跟runtime，runtime主要是看這個map是否會隨時變動，那麼這就只能使用runtime，而其他方式都只能在執行前先計算好，寫死在專案裡面。


![](/assets/f588242049c6/1*cMW6ZmpOT0rfDJ4_zha5tg.png)


總而言之，要達到相同的結果方法百百種，只要懂電腦圖學光是在unity中就可以玩出很多花樣，

補充一點，Gamma校正跟DecodeHDR沒有關係，DecodeHDR是利用a channel把rgb從\[0,1\]decode到\[ \-9999, 9999\]，用於RGBM之類的。

另外，常見的Gamma校正長得像這樣
```cpp
void main()
{
    // do super fancy lighting in linear space
    [...]
    // apply gamma correction
    float gamma = 2.2;
    FragColor.rgb = pow(fragColor.rgb, vec3(1.0/gamma));
}
```

[**Gamma Correction**](https://learnopengl.com/Advanced-Lighting/Gamma-Correction){:target="_blank"} 
[_Learn OpenGL \. com provides good and clear modern 3\.3\+ OpenGL tutorials with clear examples\. A great resource to learn…_ learnopengl\.com](https://learnopengl.com/Advanced-Lighting/Gamma-Correction){:target="_blank"}

[**Gamma、Linear、sRGB 和Unity Color Space，你真懂了吗？**](https://zhuanlan.zhihu.com/p/66558476){:target="_blank"} 
[_“为什么我渲染出来的场景，总是感觉和真实世界不像呢？” 游戏从业者或多或少都听过Linear、Gamma、sRGB和伽马校正这些术语，互联网上也有很多科普的资料，但是它们似乎又都没有讲很&\#34;清楚&\#34;。 游戏界（特…_ zhuanlan\.zhihu\.com](https://zhuanlan.zhihu.com/p/66558476){:target="_blank"}

[**Unity Color Space: Gamma vs Linear**](https://www.zhihu.com/tardis/zm/art/337052514?source_id=1003){:target="_blank"} 
[_一般情况下美术提供的Albedo等贴图是在Gamma Color Space下的，即相对于Linear Color Space，Albedo等贴图的颜色值进行了1/2\.2次方（近似）。另外一种是Normal…_ www\.zhihu\.com](https://www.zhihu.com/tardis/zm/art/337052514?source_id=1003){:target="_blank"}

但是實際測試過會發現結果與unity提供的 _GammaToLinearSpaceExact_ 結果並不一致，從code中可以發現Unity中有定義 _UNITY\_COLORSPACE\_GAMMA_ 這個Marco，進一步才發現有提供 _GammaToLinearSpace_ 和 _GammaToLinearSpaceExact_


![](/assets/f588242049c6/1*RWktCgYM-r5o59TmL1Qsjw.png)


打開就會發現，pow\(2\.2\)只是其中一部份而已。


![](/assets/f588242049c6/1*1Wk4m0qhELyEUD4iZoehcQ.png)


[**Unity Color Space: Gamma vs Linear**](https://www.zhihu.com/tardis/zm/art/337052514?source_id=1003){:target="_blank"} 
[_一般情况下美术提供的Albedo等贴图是在Gamma Color Space下的，即相对于Linear Color Space，Albedo等贴图的颜色值进行了1/2\.2次方（近似）。另外一种是Normal…_ www\.zhihu\.com](https://www.zhihu.com/tardis/zm/art/337052514?source_id=1003){:target="_blank"}

[**Unity Gamma空间还原Linear空间效果**](https://zhuanlan.zhihu.com/p/76514978){:target="_blank"} 
[_已经有很多大佬写过关于Gamma空间和Linear空间的文章了，都写的很详细了，原理也都分析的很清楚了。所以就不在细说这些了，这里说下在Unity的Gamma空间要怎么来还原linear空间的效果，主要是针对PBR的渲染效果。 …_ zhuanlan\.zhihu\.com](https://zhuanlan.zhihu.com/p/76514978){:target="_blank"}

[**unity shader 源码阅读（基础三）**](https://zhuanlan.zhihu.com/p/491961724){:target="_blank"} 
[_1、线性空间（linear）和 伽马空间（gamma） 在项目里经常有人会提到伽马校正和Unity Color Space，但很多人不知道为什么。 这里必须提到一个概念sRGB对应的…_ zhuanlan\.zhihu\.com](https://zhuanlan.zhihu.com/p/491961724){:target="_blank"}


[![](https://upload-images.jianshu.io/upload_images/26934647-faf7d65abdb1d711.png)](https://www.jianshu.com/p/a8b6ec428823){:target="_blank"}


[**How to get pixel data from maps**](https://discourse.threejs.org/t/how-to-get-pixel-data-from-maps/25966/4){:target="_blank"} 
[_Hello there\! I have a some objects in my scene\. Objects it's a bufferGeometries with different maps: Map, bumpMap and…_ discourse\.threejs\.org](https://discourse.threejs.org/t/how-to-get-pixel-data-from-maps/25966/4){:target="_blank"}

[**走进纹理科学，看穿底层逻辑，耗时的背后竟然是\. \. \. \. \. \.**](https://imgtec.eetrend.com/blog/2023/100571694.html){:target="_blank"} 
[_像素是纹理最基本的组成单位，而 Unity 有多种用 C\# 脚本读写像素数据的方法。这样就可以实现复制、更新纹理等多种功能，比如给玩家的头像加上装饰、读取地图的纹理来决定物体的摆放位置等。…_ imgtec\.eetrend\.com](https://imgtec.eetrend.com/blog/2023/100571694.html){:target="_blank"}


[![](https://unity3d.com/files/images/ogimg.jpg)](https://docs.unity3d.com/ScriptReference/Texture2D.GetPixelData.html){:target="_blank"}



[![](https://unity3d.com/files/images/ogimg.jpg)](https://docs.unity3d.com/ScriptReference/Texture2D.GetRawTextureData.html){:target="_blank"}



[![](https://p2.bahamut.com.tw/HOME/creationCover/10/0005522710_B.JPG)](https://home.gamer.com.tw/artwork.php?sn=5522710){:target="_blank"}




_[Post](https://medium.com/maochinn/unity-displacement-map-f588242049c6){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
