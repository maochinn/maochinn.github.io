---
title: "【Cosmos】Physical AI, Agent and World Model"
author: "帽捲"
date: 2025-04-16T09:53:27.594+0000
last_modified_at: 2025-06-01T08:12:52.808+0000
categories: ["Maochinn"]
tags: ["nvidia","cosmos","physical-ai","world-models","omniverse"]
description: "從今年CES就有發現NVIDIA推了一個東西叫Cosmos，之後花了一些時間研究，所以打算紀錄一下，不過在讀論文之前，我想要先在本篇介紹一些相關的名詞，包含Cosmos本身。"
image:
  path: /assets/a1549af4fef2/1*Mw5wyUgaUMwAfC7v34WZ5A.png
render_with_liquid: false
---

### 【Cosmos】Physical AI, Agent and World Model

從今年CES就有發現NVIDIA推了一個東西叫Cosmos，之後花了一些時間研究，所以打算紀錄一下，不過在讀論文之前，我想要先在本篇介紹一些相關的名詞，包含Cosmos本身。


![](/assets/a1549af4fef2/1*Mw5wyUgaUMwAfC7v34WZ5A.png)


從官網上可以看到是這樣寫的Develop world foundation models to advance physical Al\. 同時論文的標題是這樣寫的 [Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"} 。


[![](https://www.nvidia.com/content/dam/en-zz/Solutions/ai/cosmos/nvidia-cosmos-og.jpg)](https://www.nvidia.com/en-us/ai/cosmos/){:target="_blank"}


其中WFM\(World Foundation Model\)這個詞不停地被使用，事實上，他對應的就是Github上的 [Cosmos\-Predict1](https://github.com/nvidia-cosmos/cosmos-predict1){:target="_blank"} ，目針對Cosmos有三個sub\-project
1. [Cosmos\-Predict1](https://github.com/nvidia-cosmos/cosmos-predict1){:target="_blank"} is a collection of general\-purpose world foundation models for Physical AI that can be fine\-tuned into customized world models for downstream applications\.
2. [Cosmos\-Transfer1](https://github.com/nvidia-cosmos/cosmos-transfer1){:target="_blank"} is a world\-to\-world transfer model designed to bridge the perceptual divide between simulated and real\-world environments\.
3. [Cosmos\-Reason1](https://github.com/nvidia-cosmos/cosmos-reason1){:target="_blank"} models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain\-of\-thought reasoning processes\.


所以本篇我想嘗試從舉例的方式來稍微解釋一下，何謂WFM以及相關的名詞，也就是首先我會介紹Cosmos\-Predict1，因為它也是論文 [Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"} 中主要提到的，所謂的World Foundation model。
### Pre\-trained World Foundation Model

幸運的是，Cosmos\-Predict1在NIM上也已經有一些DEMO可以跑例如 [**cosmos\-predict1–7b**](https://build.nvidia.com/nvidia/cosmos-predict1-7b){:target="_blank"} 和 [cosmos\-predict1–5b](https://build.nvidia.com/nvidia/cosmos-predict1-5b){:target="_blank"} 。

前者有兩個模式分別是Text\-to\-World和Image\-to\-World，光看字面上的意思其實不太知道輸出是什麼，但只要實際run過大概就知道輸出其實就是video

後者是比較小的model，但是它是比較典型的應用，也就是Video\-to\-World，簡單來說，就是輸入一小段影片，然後接續生成未來的影片。


![](/assets/a1549af4fef2/0*hBbBHAeAgpKLupNT)


換言之，我們可以比較粗淺的從輸入輸出理解所謂的world foundation model就是輸出影片的AI，他的輸入可能是如上所述的可能是Text、Image或是Video，也有可能同時有多種類的輸入。

所以無論在論文 [Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"} 或是在Github上 [Cosmos\-Predict1](https://github.com/nvidia-cosmos/cosmos-predict1){:target="_blank"} 可以看到這張圖


![](/assets/a1549af4fef2/0*pTo5Cu9wGMiGHyYx.png)


概念來說，就是輸入現在的狀態以及此刻的action，以此輸出未來的狀態，因為action會對未來造成變化，如果以機器人來舉例，那就是輸入機器人此刻的靜止狀態以及此刻action的控制信號，比如此刻的機器人輪子往前轉，那我們期待輸出的未來中，機器人會處於往前的狀態。

特別的是，Cosmos使用video來表示世界的狀態，換言之，無論機器人是靜止還是運動都是用video來表示，而不是用某種數值，例如從速度=0 \-&gt; 速度=100之類的，這麼做的好處是，泛化性比較高，什麼樣的狀態理論上都可以使用影片來表達，資料的收集可能是相機拍攝的也有可能是電腦算繪的。

因此，更好理解的名稱應該是Video\-to\-VideoWorld model，與其說它是生成影片的AI model，不如說這是生成世界的model，不過這個世界的representation是用video這樣的格式。


![[Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"}](/assets/a1549af4fef2/1*pipBXJmUr1jsCKDXr_w1Ug.png)

[Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"}

看論文中的例子可以知道，我們可以透過給定初始的畫面，然後一個action或者是control signal，將對未來的描述作為prompt輸入到model，然後就會產生未來，而Cosmos要做的事情是，他們希望這些model是符合現實物理的，講白了就是不會出現奇怪的變形或是違反基本物理規則的未來。

不過可以注意到，Cosmos\-Predict1是WFM，他之所以foundation就是因為我們預期還會再經過Post\-training，這樣的概念就像是一般的LLM，有資本的大公司會訓練出比較general的大model，然後一般的公司在fine\-tune成自己需要的model，而world foundation model就是事先先學過基本的物理規則的影片生成AI，以此為基礎再去針對特定場域進一步學習，確保在特定場域的不會生成出奇怪的物理現象。
### Post\-training WFM \(World Model\)

因此實際應用上，我們還是會需要進一步對WFM做post\-training，我這邊姑且稱訓練出來的model為 **world model** ，這個model是針對不同場域的問題來處理，因為不同情境的問題可能會用不同的方式來表示action，最直覺的方式就是直接使用text來描述，因為這是沿用WFM的輸入輸出，例如論文中的例子


![[Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"}](/assets/a1549af4fef2/0*qhukwfhNGnCG6BG3)

[Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"}

給一開始的畫面，然後給定你想要看到未來機器人做的動作，然後就會生成這樣的未來給你，這跟前面WFM的差異在於，這個World model可能會針對機器人第一人稱視角的影像做進一步training，確保這樣的視角的效果是準確且穩定的。

但既然是post\-training，action的形式也不一定是text，只要有足夠的訓練集，可以使用其他更適合的action，例如sensor此刻的數值可能相較於text更加具體和準確，例如


![[Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"}](/assets/a1549af4fef2/0*XvxAU72vCH52JVKB)

[Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"}

一樣給定初始的影像，然後action是此刻機器手臂的速度之類的數值，以此生成下一個瞬間的畫面，這個概念就像是S = S0 \+ Vt，只要有此刻的位置和速度就可以預測下個瞬間的位置，也因為這邊需要預測下一個瞬間，這樣生成的影像準確度提高就變得相對容易。

上面的例子要說明的是，這些都屬於post\-training world model，他們是從world foundation model進一步訓練出來的，依據自己的需求調整輸入輸出，也可以根據自己的使用場景提供訓練資料。
### Policy Model

只不過，說到底，world model這聽起來就只是生成影片/影像的AI，具體來說有甚麼用處？例如機器人具體到底要怎麼行動，這個就牽涉到policy model，一個比較直覺的範例在論文中有提到的


![[Zero\-Shot Robotic Manipulation with Pretrained Image\-Editing Diffusion Models](https://arxiv.org/abs/2310.10639){:target="_blank"}](/assets/a1549af4fef2/0*xZ6vBwZKlpVCQtRo)

[Zero\-Shot Robotic Manipulation with Pretrained Image\-Editing Diffusion Models](https://arxiv.org/abs/2310.10639){:target="_blank"}

簡單來說，一樣給定初始影像，使用者並將機器人想要做的事情寫成text prompt，生成下一個瞬間的影像，然後將先後兩張影像交給policy model，也就是實際控制機器人的model，讓他依據兩張圖的差異去決定該做出甚麼動作，一種比較傳統的做法可以拿來想像，就是利用light flow之類的方式，如此一幀一幀逐步完成目標。

換言之，我們把一個複雜的goal切成多個subgoals，並且交由兩個model去完成，world model負責生成未來的影像，policy model只需要專注在比對兩張圖片的差異並且做出動作即可，這個概念上有點像是semi\-implicit，先外插猜測未來，然後再回頭內插出下個瞬間。

到此，我們可以整理一下，目前提到總共有三個model，分別是World Foundation model, World Model以及Policy Model，其中，實際運行在機器人的Model是Policy Model，World Model可能會同時運行，但通常不會，因為World Model通常很龐大，除非像上面的例子每次只需要產生一張影像，那可以用比較小規模的world model，不然典型的例子應該是將Policy Model造成的結果作為World model的輸入，將world model的輸出當作真實世界的未來，以此fine\-tune我們的model。
### The Agent

這個東西就會先牽涉到agent，因為我們會將policy model包裝成agent,然後將其放入虛擬世界中與world model互動，這個就是policy learning，這是因為在現實中fine\-tune的成本太高，也就是訓練資料的取得太困難，因此要先盡可能地在虛擬世界中模擬，直到準確度達到合格的水準。

因此，agent可以簡單的理解成是機器人中的 **軟體** 部分，將sensor，例如相機的影像傳到真正做action的policy model上，等到model輸出action在將其傳到個別的actuator，例如馬達上，換言之，就是將policy model加上那些與世界互動的介面，這樣的概念類似於現在常見的，基於LLM的agent，只是我們是將video作為prompt輸入，然後輸出action。

那在虛擬世界中，最簡單的方式就是直接將policy model輸出的action作為world model的輸入，再加上目前相機的影像也作為輸入，然後輸出的未來影像就會是做完這個動作的結果，可以用這個結果作為Policy model的答案，看看符不符合policy model的期待，並且作為下次的的輸入，讓Policy model決定在下一個瞬間要做甚麼動作。

這樣個感覺有點像是將world model完全做為一個模擬引擎使用，直覺上可能會覺得不是這麼準確，因此實際的應用上可能還是會將agent放在一個有物理引擎的虛擬世界之中模擬，例如Omniverse，同時會利用world model將模擬出現的未來再修正一次，也就是Omniverse會產生下一個瞬間的影像，然後利用world model對這個影像做一個濾鏡，一個符合現實物理的濾鏡，確保未來的影像足夠真實。

事實上，這個world model這就是開頭提到的其中一個sub\-project，因此，虛擬的世界中可能包含了world model以外的東西，但是world model是為了讓影像變得更加符合現實世界的物理現象，同時，agent也不只是policy model，也包含如何將影像傳到policy model以及如何將policy model的輸出適當的與世界互動。
### Physical AI system

當我們在虛擬世界中訓練好的policy model，我們就可以將整個agent放到現實中的硬體上，而這整個system就是Physical AI system，換言之，如果說agent是機器人中的軟體部分，那機器人的軟硬體合起來就是Physical AI system。

換言之，我們需要搞清楚我們到底目標是甚麼？是要做一個Physical AI system？還是agent就好？world model對我們來說，是目標還是手段。
### 結論

總之，本篇為了後續理解方便，刻意的挑出幾個詞來解釋，如果範圍從大到小可以列成這樣。
- Physical AI system \(hardware and software\)
- Agent \(software\)
- Policy Model \(AI model\)
- World model \(for enhanced policy learning\)
- World foundation model \(A general world model\)


解釋上可能沒有那麼準確，但是我想要釐清個別名詞所代表的意義，也搞清楚Cosmos是什麼，讓我們看看論文的標題， [Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"} ，Cosmos並不是model的名稱，他是一個平台，這個平台是關於World foundation model的，它包含了很多的WFM以及相關的技術，而這個平台的目標是為了幫助打造Physical AI。

回到開頭，看看論文的標題， [Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/abs/2501.03575){:target="_blank"} ，Cosmos並不是model的名稱，他是一個平台，這個平台是關於World foundation model的，而這個平台的目標是為了幫助打造Physical AI。

如果一樣用機器人來舉例，機器人本身就是一個Physical AI system，你會需要硬體與軟體，軟體就是agent，而agent其中重要的部分就是AI model，或者更準確說是policy model，而這個Policy model該怎麼被有效的訓練，NVIDIA提出的解答就是world mode，讓policy model在虛擬的世界中訓練好，只要世界越真實，那訓練的效果就越好，但是這樣的world model要訓練的好需要大量的資料，因此，Cosmos這個平台提供了WFM，讓你不需要重頭開始training，只需要用相對少的資料來訓練自己的world model即可。

感謝你的閱讀，如果你對我的文章對你有所幫助或是意見歡迎回覆，如果你想要支持我可以：
- 拍個手👋，或是分享一些想法💬
- [追蹤我的頁面](https://medium.com/@maochinn){:target="_blank"}
- [訂閱我的專欄](https://medium.com/maochinn){:target="_blank"}
- [透過LinkedIn聯繫我](https://www.linkedin.com/in/chih-wei-chang-6526801b2/){:target="_blank"}


或是觀看我其他系列文章
- [【Omniverse】學習筆記 — 03：OpenUSD](../be14a4a5704f/)
- [【電腦圖學】學習筆記 — 00：OpenGL](../fa7105f59ecd/)
- [【Cosmos】Paper Reading: Cosmos World Foundation Model Platform for Physical AI](../a6b5ff405748/)
- [【工作】SIGGRAPH Asia 2024 東京出差紀錄 / 攻略指南](../bf50ed0bf508/)



_[Post](https://medium.com/maochinn/cosmos-physical-ai-agent-and-world-model-a1549af4fef2){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
